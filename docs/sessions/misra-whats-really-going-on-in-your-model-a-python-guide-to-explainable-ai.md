# What’s Really Going on in Your Model? A Python Guide to Explainable AI

**Speakers:** Yashasvi Misra

**Session Type:** 30-mins talk session

**Level:** Beginner

**Language:** English

**Category:** Machine Learning or AI

## Abstract

We’ve all been there, your machine learning model performs well in testing, but when it comes time to explain why it made a specific prediction, things get murky. In many real-world applications, especially in domains like healthcare, finance, or operations, being able to explain your model isn’t just helpful it’s critical. This talk is a practical walkthrough of explainable AI (XAI) tools in Python, aimed at data scientists and engineers who want to make their models more transparent and trustworthy. We’ll cover libraries like SHAP, LIME, and Captum, and show how to use them to generate both local and global explanations for models ranging from random forests to deep neural nets. You’ll see hands-on examples, common pitfalls to avoid, and ideas for integrating interpretability into your workflow whether you’re trying to debug your model or justify its predictions to a non-technical stakeholder. If you’ve ever wanted to better understand your own models or help others trust them this session is for you.


## About the Speaker(s)

### Yashasvi Misra

*Speaker bio will be available soon.*

